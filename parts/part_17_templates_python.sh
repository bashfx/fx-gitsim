################################################################################
# Python Template Module
################################################################################

# Register this template with the core system
_register_template "python" "Python project with modern tooling" "py"

################################################################################
# Python Template Implementation
################################################################################

# Main creation function (standard interface)
_create_python_template() {
    local target_dir="$1"
    local project_name="$2"
    local package_name="${project_name//-/_}"  # Convert hyphens to underscores
    
    # Create Python project structure (src-layout)
    mkdir -p "$target_dir"/{src/$package_name,tests,docs}
    
    # Generate Python project files
    __print_pyproject_toml "$target_dir/pyproject.toml" "$project_name" "$package_name"
    __print_requirements_txt "$target_dir/requirements.txt"
    __print_requirements_dev_txt "$target_dir/requirements-dev.txt"
    __print_python_init "$target_dir/src/$package_name/__init__.py" "$project_name"
    __print_python_main "$target_dir/src/$package_name/main.py" "$project_name" "$package_name"
    __print_python_utils "$target_dir/src/$package_name/utils.py" "$package_name"
    __print_python_config "$target_dir/src/$package_name/config.py" "$package_name"
    __print_python_test_main "$target_dir/tests/test_main.py" "$package_name"
    __print_python_test_utils "$target_dir/tests/test_utils.py" "$package_name"
    __print_python_conftest "$target_dir/tests/conftest.py"
    __print_python_gitignore "$target_dir/.gitignore"
    __print_setup_cfg "$target_dir/setup.cfg"
    __print_python_version "$target_dir/.python-version"
    __print_makefile "$target_dir/Makefile" "$project_name"
    __print_readme_md "$target_dir/README.md" "$project_name" "Python"
    
    # Create empty __init__.py for tests
    touch "$target_dir/tests/__init__.py"
    
    trace "Created Python project structure in $target_dir"
    return 0
}

# Template preview function
_show_python_template() {
    cat << 'EOF'
Python project structure (src-layout):
  pyproject.toml      - Modern Python packaging configuration
  requirements.txt    - Production dependencies
  requirements-dev.txt - Development dependencies
  setup.cfg           - Tool configuration (flake8, pytest, etc.)
  Makefile           - Development automation
  .python-version    - Python version specification
  src/
    package/
      __init__.py     - Package initialization
      main.py         - Main application logic
      utils.py        - Utility functions
      config.py       - Configuration management
  tests/
    __init__.py       - Test package init
    conftest.py       - Pytest configuration
    test_main.py      - Main module tests
    test_utils.py     - Utils module tests
  .gitignore          - Python-specific ignore patterns
  README.md           - Project documentation

Features: Modern src-layout, pytest, type hints, dataclasses
EOF
}

################################################################################
# Python File Generators
################################################################################

__print_pyproject_toml() {
    local file="$1"
    local project_name="$2"
    local package_name="$3"
    
    cat > "$file" << EOF
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "$project_name"
version = "1.0.0"
description = "A sample Python project generated by GitSim"
authors = [
    {name = "$SIM_USER", email = "${SIM_USER}@example.com"}
]
maintainers = [
    {name = "$SIM_USER", email = "${SIM_USER}@example.com"}
]
readme = "README.md"
license = {text = "MIT"}
keywords = ["sample", "gitsim", "python"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
requires-python = ">=3.8"
dependencies = [
    "click>=8.0.0",
    "requests>=2.28.0",
    "pydantic>=2.0.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0",
    "pre-commit>=3.0.0",
]
docs = [
    "sphinx>=6.0.0",
    "sphinx-rtd-theme>=1.2.0",
]

[project.urls]
Homepage = "https://github.com/${SIM_USER}/${project_name}"
Documentation = "https://github.com/${SIM_USER}/${project_name}/blob/main/README.md"
Repository = "https://github.com/${SIM_USER}/${project_name}.git"
"Bug Tracker" = "https://github.com/${SIM_USER}/${project_name}/issues"

[project.scripts]
$project_name = "${package_name}.main:main"

[tool.setuptools.packages.find]
where = ["src"]
include = ["${package_name}*"]
exclude = ["tests*"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "--strict-markers",
    "--strict-config",
    "--verbose",
    "--cov=${package_name}",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-fail-under=80"
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests"
]

[tool.black]
line-length = 88
target-version = ["py38", "py39", "py310", "py311"]
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
line_length = 88
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

[[tool.mypy.overrides]]
module = "tests.*"
ignore_errors = true
EOF
}

__print_requirements_txt() {
    local file="$1"
    
    cat > "$file" << 'EOF'
# Core dependencies
click>=8.0.0,<9.0.0
requests>=2.28.0,<3.0.0
pydantic>=2.0.0,<3.0.0
python-dotenv>=1.0.0,<2.0.0

# Optional: uncomment if needed
# pandas>=2.0.0,<3.0.0
# numpy>=1.24.0,<2.0.0
# sqlalchemy>=2.0.0,<3.0.0
# fastapi>=0.100.0,<1.0.0
EOF
}

__print_requirements_dev_txt() {
    local file="$1"
    
    cat > "$file" << 'EOF'
# Include production requirements
-r requirements.txt

# Development and testing
pytest>=7.0.0,<8.0.0
pytest-cov>=4.0.0,<5.0.0
pytest-mock>=3.10.0,<4.0.0
pytest-asyncio>=0.21.0,<1.0.0

# Code formatting and linting
black>=23.0.0,<24.0.0
isort>=5.12.0,<6.0.0
flake8>=6.0.0,<7.0.0
mypy>=1.0.0,<2.0.0

# Pre-commit hooks
pre-commit>=3.0.0,<4.0.0

# Documentation
sphinx>=6.0.0,<7.0.0
sphinx-rtd-theme>=1.2.0,<2.0.0

# Development utilities
ipython>=8.0.0,<9.0.0
jupyter>=1.0.0,<2.0.0
tox>=4.0.0,<5.0.0
EOF
}

__print_python_init() {
    local file="$1"
    local project_name="$2"
    
    cat > "$file" << EOF
"""
$project_name - A sample Python project generated by GitSim.

This package provides basic functionality for demonstration and testing purposes.
"""

__version__ = "1.0.0"
__author__ = "$SIM_USER"
__email__ = "${SIM_USER}@example.com"

# Import main functionality for easy access
from .main import main, Application, greet
from .utils import format_message, validate_email, timer
from .config import Config, get_config

__all__ = [
    "main",
    "Application", 
    "greet",
    "format_message",
    "validate_email",
    "timer",
    "Config",
    "get_config",
    "__version__",
    "__author__",
    "__email__",
]
EOF
}

__print_python_main() {
    local file="$1"
    local project_name="$2"
    local package_name="$3"
    
    cat > "$file" << EOF
"""
Main application module for $project_name.

This module contains the primary application logic and command-line interface.
"""

import sys
import asyncio
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path

import click
from pydantic import BaseModel, validator

from .utils import format_message, validate_email, timer
from .config import get_config, Config


class UserModel(BaseModel):
    """User model with validation."""
    name: str
    email: str
    age: Optional[int] = None
    
    @validator('email')
    def validate_email_format(cls, v):
        if not validate_email(v):
            raise ValueError('Invalid email format')
        return v
    
    @validator('age')
    def validate_age_range(cls, v):
        if v is not None and (v < 0 or v > 150):
            raise ValueError('Age must be between 0 and 150')
        return v


@dataclass
class ApplicationState:
    """Application state management."""
    config: Config
    users: List[UserModel] = field(default_factory=list)
    status: str = "initialized"
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        self.metadata.update({
            "version": "1.0.0",
            "author": "$SIM_USER",
            "created": "Generated by GitSim"
        })


class Application:
    """Main application class for $project_name."""
    
    def __init__(self, config_path: Optional[Path] = None):
        """Initialize the application."""
        self.config = get_config(config_path)
        self.state = ApplicationState(config=self.config)
        
    async def initialize(self) -> None:
        """Initialize the application asynchronously."""
        print(format_message("info", "Initializing $project_name..."))
        
        # Simulate async initialization
        await asyncio.sleep(0.1)
        
        self.state.status = "running"
        print(format_message("success", "Application initialized successfully"))
    
    def add_user(self, name: str, email: str, age: Optional[int] = None) -> UserModel:
        """Add a user to the application."""
        try:
            user = UserModel(name=name, email=email, age=age)
            self.state.users.append(user)
            print(format_message("info", f"Added user: {user.name}"))
            return user
        except Exception as e:
            print(format_message("error", f"Failed to add user: {e}"))
            raise
    
    def list_users(self) -> List[UserModel]:
        """List all users."""
        return self.state.users
    
    def get_status(self) -> Dict[str, Any]:
        """Get application status."""
        return {
            "status": self.state.status,
            "user_count": len(self.state.users),
            "config": self.config.model_dump(),
            "metadata": self.state.metadata
        }
    
    async def run_demo(self) -> None:
        """Run a demonstration of the application."""
        print(format_message("info", "Running $project_name demonstration"))
        
        # Add some sample users
        sample_users = [
            ("Alice Johnson", "alice@example.com", 30),
            ("Bob Smith", "bob@example.com", 25),
            ("Carol Williams", "carol@example.com", None),
        ]
        
        for name, email, age in sample_users:
            try:
                with timer(f"Adding user {name}"):
                    await asyncio.sleep(0.05)  # Simulate async work
                    self.add_user(name, email, age)
            except Exception as e:
                print(format_message("error", f"Failed to add {name}: {e}"))
        
        # Display results
        users = self.list_users()
        print(f"\nApplication now has {len(users)} users:")
        for user in users:
            age_str = f", age {user.age}" if user.age else ""
            print(f"  - {user.name} ({user.email}{age_str})")
        
        print(f"\nApplication status: {self.get_status()}")


def greet(name: str, count: int = 1) -> str:
    """Create a greeting message."""
    if not name:
        raise ValueError("Name cannot be empty")
    
    greetings = []
    for i in range(count):
        if count > 1:
            greetings.append(f"{i+1}: Hello, {name} from $project_name!")
        else:
            greetings.append(f"Hello, {name} from $project_name!")
    
    return "\n".join(greetings)


@click.group()
@click.version_option(version="1.0.0")
@click.option("--config", type=click.Path(exists=True), help="Configuration file path")
@click.option("--verbose", "-v", is_flag=True, help="Enable verbose output")
@click.pass_context
def cli(ctx, config, verbose):
    """$project_name - A sample Python application."""
    ctx.ensure_object(dict)
    ctx.obj['config_path'] = Path(config) if config else None
    ctx.obj['verbose'] = verbose


@cli.command()
@click.argument("name")
@click.option("--count", "-c", default=1, help="Number of greetings")
@click.pass_context
def hello(ctx, name, count):
    """Greet someone by name."""
    try:
        message = greet(name, count)
        print(message)
    except Exception as e:
        print(format_message("error", str(e)))
        sys.exit(1)


@cli.command()
@click.pass_context
def demo(ctx):
    """Run a demonstration of the application."""
    async def run_demo():
        app = Application(ctx.obj['config_path'])
        await app.initialize()
        await app.run_demo()
    
    try:
        asyncio.run(run_demo())
    except Exception as e:
        print(format_message("error", f"Demo failed: {e}"))
        sys.exit(1)


@cli.command()
@click.argument("name")
@click.argument("email") 
@click.option("--age", type=int, help="User age")
@click.pass_context
def add_user(ctx, name, email, age):
    """Add a user to the application."""
    try:
        app = Application(ctx.obj['config_path'])
        user = app.add_user(name, email, age)
        print(f"Added user: {user.model_dump_json(indent=2)}")
    except Exception as e:
        print(format_message("error", str(e)))
        sys.exit(1)


@cli.command()
@click.pass_context
def status(ctx):
    """Show application status."""
    try:
        app = Application(ctx.obj['config_path'])
        status_info = app.get_status()
        print(f"Status: {status_info}")
    except Exception as e:
        print(format_message("error", str(e)))
        sys.exit(1)


def main() -> None:
    """Main entry point for the application."""
    cli()


if __name__ == "__main__":
    main()
EOF
}

__print_python_utils() {
    local file="$1"
    local package_name="$2"
    
    cat > "$file" << EOF
"""
Utility functions for $package_name.

This module provides common utility functions used throughout the application.
"""

import re
import time
import json
from typing import Any, Dict, Optional, Union
from contextlib import contextmanager
from datetime import datetime, timezone
from pathlib import Path


def format_message(level: str, message: str) -> str:
    """
    Format a log message with timestamp and level.
    
    Args:
        level: Log level (info, warn, error, success, debug)
        message: Message to format
        
    Returns:
        Formatted message string
    """
    timestamp = datetime.now(timezone.utc).isoformat()
    level_upper = level.upper().ljust(7)
    
    # Add color codes for terminal output
    colors = {
        'info': '\033[36m',     # Cyan
        'warn': '\033[33m',     # Yellow  
        'error': '\033[31m',    # Red
        'success': '\033[32m',  # Green
        'debug': '\033[90m',    # Dark gray
        'reset': '\033[0m'      # Reset
    }
    
    color = colors.get(level, colors['reset'])
    reset = colors['reset']
    
    return f"[{timestamp}] {color}{level_upper}{reset} {message}"


def validate_email(email: str) -> bool:
    """
    Validate email address format.
    
    Args:
        email: Email address to validate
        
    Returns:
        True if email format is valid
    """
    if not email or not isinstance(email, str):
        return False
        
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))


def safe_json_loads(data: Union[str, bytes]) -> Optional[Dict[str, Any]]:
    """
    Safely parse JSON data with error handling.
    
    Args:
        data: JSON string or bytes to parse
        
    Returns:
        Parsed JSON data or None if parsing fails
    """
    try:
        if isinstance(data, bytes):
            data = data.decode('utf-8')
        return json.loads(data)
    except (json.JSONDecodeError, UnicodeDecodeError, TypeError):
        return None


def safe_json_dumps(data: Any, indent: Optional[int] = None) -> Optional[str]:
    """
    Safely serialize data to JSON with error handling.
    
    Args:
        data: Data to serialize
        indent: JSON indentation level
        
    Returns:
        JSON string or None if serialization fails
    """
    try:
        return json.dumps(data, indent=indent, default=str)
    except (TypeError, ValueError):
        return None


def read_file_safe(file_path: Union[str, Path], encoding: str = 'utf-8') -> Optional[str]:
    """
    Safely read file content with error handling.
    
    Args:
        file_path: Path to file
        encoding: File encoding
        
    Returns:
        File content or None if reading fails
    """
    try:
        path = Path(file_path)
        if not path.exists():
            return None
        return path.read_text(encoding=encoding)
    except (OSError, UnicodeDecodeError):
        return None


def write_file_safe(file_path: Union[str, Path], content: str, encoding: str = 'utf-8') -> bool:
    """
    Safely write content to file with error handling.
    
    Args:
        file_path: Path to file
        content: Content to write
        encoding: File encoding
        
    Returns:
        True if write succeeded
    """
    try:
        path = Path(file_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(content, encoding=encoding)
        return True
    except OSError:
        return False


@contextmanager
def timer(operation: str = "Operation"):
    """
    Context manager to time operations.
    
    Args:
        operation: Description of the operation being timed
        
    Yields:
        None
    """
    start_time = time.time()
    try:
        print(format_message("debug", f"Starting {operation}..."))
        yield
    finally:
        end_time = time.time()
        duration = end_time - start_time
        print(format_message("debug", f"{operation} completed in {duration:.3f}s"))


def deep_merge_dicts(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:
    """
    Deep merge two dictionaries.
    
    Args:
        dict1: First dictionary
        dict2: Second dictionary (takes precedence)
        
    Returns:
        Merged dictionary
    """
    result = dict1.copy()
    
    for key, value in dict2.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge_dicts(result[key], value)
        else:
            result[key] = value
    
    return result


def truncate_string(text: str, max_length: int, suffix: str = "...") -> str:
    """
    Truncate string to maximum length with suffix.
    
    Args:
        text: String to truncate
        max_length: Maximum length
        suffix: Suffix to add if truncated
        
    Returns:
        Truncated string
    """
    if len(text) <= max_length:
        return text
    
    if max_length <= len(suffix):
        return text[:max_length]
    
    return text[:max_length - len(suffix)] + suffix


class RetryError(Exception):
    """Exception raised when retry attempts are exhausted."""
    pass


def retry_with_backoff(
    func,
    max_retries: int = 3,
    base_delay: float = 1.0,
    backoff_factor: float = 2.0,
    exceptions: tuple = (Exception,)
):
    """
    Decorator to retry function with exponential backoff.
    
    Args:
        func: Function to retry
        max_retries: Maximum number of retry attempts
        base_delay: Base delay in seconds
        backoff_factor: Backoff multiplication factor
        exceptions: Tuple of exceptions to catch and retry
        
    Returns:
        Decorated function
    """
    def wrapper(*args, **kwargs):
        last_exception = None
        
        for attempt in range(max_retries + 1):
            try:
                return func(*args, **kwargs)
            except exceptions as e:
                last_exception = e
                
                if attempt == max_retries:
                    break
                
                delay = base_delay * (backoff_factor ** attempt)
                print(format_message("warn", f"Retry {attempt + 1}/{max_retries} after {delay:.1f}s"))
                time.sleep(delay)
        
        raise RetryError(f"Function failed after {max_retries} retries: {last_exception}")
    
    return wrapper
EOF
}

__print_python_config() {
    local file="$1"
    local package_name="$2"
    
    cat > "$file" << EOF
"""
Configuration management for $package_name.

This module handles application configuration loading and validation.
"""

import os
from pathlib import Path
from typing import Optional, Dict, Any, List
from pydantic import BaseModel, Field, validator
from dotenv import load_dotenv

from .utils import read_file_safe, safe_json_loads


class DatabaseConfig(BaseModel):
    """Database configuration."""
    host: str = "localhost"
    port: int = Field(5432, ge=1, le=65535)
    database: str = "${package_name}_db"
    username: str = "user"
    password: str = "password"
    ssl_mode: str = Field("prefer", regex="^(disable|allow|prefer|require)$")
    pool_size: int = Field(10, ge=1, le=100)


class LoggingConfig(BaseModel):
    """Logging configuration."""
    level: str = Field("INFO", regex="^(DEBUG|INFO|WARNING|ERROR|CRITICAL)$")
    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_path: Optional[str] = None
    max_bytes: int = Field(10485760, ge=1024)  # 10MB
    backup_count: int = Field(3, ge=0, le=10)


class Config(BaseModel):
    """Main application configuration."""
    
    # Application settings
    debug: bool = False
    testing: bool = False
    secret_key: str = "your-secret-key-here-change-in-production"
    
    # Server settings
    host: str = "localhost"
    port: int = Field(8000, ge=1, le=65535)
    workers: int = Field(4, ge=1, le=32)
    
    # Database configuration
    database: DatabaseConfig = Field(default_factory=DatabaseConfig)
    
    # Logging configuration
    logging: LoggingConfig = Field(default_factory=LoggingConfig)
    
    # Feature flags
    enable_metrics: bool = True
    enable_health_check: bool = True
    enable_cors: bool = True
    
    # External service URLs
    api_base_url: str = "https://api.example.com"
    timeout_seconds: int = Field(30, ge=1, le=300)
    
    # File paths
    data_directory: str = "./data"
    temp_directory: str = "./tmp"
    
    @validator('secret_key')
    def secret_key_not_default(cls, v):
        """Ensure secret key is changed from default in production."""
        if not cls.__config__.debug and v == "your-secret-key-here-change-in-production":
            raise ValueError("Secret key must be changed in production")
        return v
    
    @validator('data_directory', 'temp_directory')
    def ensure_directory_exists(cls, v):
        """Ensure directories exist."""
        path = Path(v)
        path.mkdir(parents=True, exist_ok=True)
        return str(path.resolve())
    
    class Config:
        """Pydantic configuration."""
        env_prefix = "${package_name}_"
        case_sensitive = False


def load_config_from_env() -> Dict[str, Any]:
    """
    Load configuration from environment variables.
    
    Returns:
        Dictionary of configuration values
    """
    # Load .env file if it exists
    env_path = Path('.env')
    if env_path.exists():
        load_dotenv(env_path)
    
    config_dict = {}
    prefix = f"${package_name}_".upper()
    
    for key, value in os.environ.items():
        if key.startswith(prefix):
            # Remove prefix and convert to lowercase
            config_key = key[len(prefix):].lower()
            
            # Handle nested configuration
            if '__' in config_key:
                parts = config_key.split('__')
                current = config_dict
                for part in parts[:-1]:
                    if part not in current:
                        current[part] = {}
                    current = current[part]
                current[parts[-1]] = value
            else:
                config_dict[config_key] = value
    
    return config_dict


def load_config_from_file(file_path: Path) -> Dict[str, Any]:
    """
    Load configuration from JSON file.
    
    Args:
        file_path: Path to configuration file
        
    Returns:
        Dictionary of configuration values
    """
    content = read_file_safe(file_path)
    if not content:
        return {}
    
    config_data = safe_json_loads(content)
    return config_data or {}


def get_config(config_path: Optional[Path] = None) -> Config:
    """
    Get application configuration.
    
    Args:
        config_path: Optional path to configuration file
        
    Returns:
        Configuration object
    """
    config_dict = {}
    
    # Load from file if provided
    if config_path and config_path.exists():
        file_config = load_config_from_file(config_path)
        config_dict.update(file_config)
    
    # Load from environment (takes precedence)
    env_config = load_config_from_env()
    config_dict.update(env_config)
    
    # Create and validate configuration
    try:
        return Config(**config_dict)
    except Exception as e:
        raise ValueError(f"Configuration validation failed: {e}")


def get_database_url(config: Config) -> str:
    """
    Generate database URL from configuration.
    
    Args:
        config: Configuration object
        
    Returns:
        Database connection URL
    """
    db = config.database
    return f"postgresql://{db.username}:{db.password}@{db.host}:{db.port}/{db.database}"


# Global configuration instance
_config: Optional[Config] = None


def get_global_config() -> Config:
    """
    Get global configuration instance.
    
    Returns:
        Global configuration object
    """
    global _config
    if _config is None:
        _config = get_config()
    return _config


def set_global_config(config: Config) -> None:
    """
    Set global configuration instance.
    
    Args:
        config: Configuration object to set
    """
    global _config
    _config = config
EOF
}

__print_python_test_main() {
    local file="$1"
    local package_name="$2"
    
    cat > "$file" << EOF
"""
Tests for main module.
"""

import pytest
from unittest.mock import patch, AsyncMock
from pydantic import ValidationError

from ${package_name}.main import (
    greet, 
    Application, 
    UserModel, 
    ApplicationState
)
from ${package_name}.config import Config


class TestUserModel:
    """Test UserModel validation."""
    
    def test_valid_user_creation(self):
        """Test creating a valid user."""
        user = UserModel(
            name="Alice Johnson",
            email="alice@example.com",
            age=30
        )
        assert user.name == "Alice Johnson"
        assert user.email == "alice@example.com"
        assert user.age == 30
    
    def test_user_without_age(self):
        """Test creating user without age."""
        user = UserModel(
            name="Bob Smith",
            email="bob@example.com"
        )
        assert user.name == "Bob Smith"
        assert user.email == "bob@example.com"
        assert user.age is None
    
    def test_invalid_email(self):
        """Test user creation with invalid email."""
        with pytest.raises(ValidationError, match="Invalid email format"):
            UserModel(
                name="Invalid User",
                email="not-an-email"
            )
    
    def test_invalid_age(self):
        """Test user creation with invalid age."""
        with pytest.raises(ValidationError, match="Age must be between 0 and 150"):
            UserModel(
                name="Old User",
                email="old@example.com",
                age=200
            )


class TestApplicationState:
    """Test ApplicationState dataclass."""
    
    def test_application_state_creation(self):
        """Test creating application state."""
        config = Config()
        state = ApplicationState(config=config)
        
        assert state.config == config
        assert state.users == []
        assert state.status == "initialized"
        assert "version" in state.metadata
        assert "author" in state.metadata


class TestGreetFunction:
    """Test greet function."""
    
    def test_single_greeting(self):
        """Test single greeting."""
        result = greet("Alice")
        expected = "Hello, Alice from ${package_name}!"
        assert result == expected
    
    def test_multiple_greetings(self):
        """Test multiple greetings."""
        result = greet("Bob", count=3)
        lines = result.split("\\n")
        assert len(lines) == 3
        assert lines[0] == "1: Hello, Bob from ${package_name}!"
        assert lines[1] == "2: Hello, Bob from ${package_name}!"
        assert lines[2] == "3: Hello, Bob from ${package_name}!"
    
    def test_empty_name_raises_error(self):
        """Test that empty name raises error."""
        with pytest.raises(ValueError, match="Name cannot be empty"):
            greet("")


class TestApplication:
    """Test Application class."""
    
    def test_application_initialization(self):
        """Test application initialization."""
        app = Application()
        assert app.config is not None
        assert app.state.status == "initialized"
        assert len(app.state.users) == 0
    
    @pytest.mark.asyncio
    async def test_application_async_initialization(self):
        """Test application async initialization."""
        app = Application()
        await app.initialize()
        assert app.state.status == "running"
    
    def test_add_valid_user(self):
        """Test adding a valid user."""
        app = Application()
        user = app.add_user("Alice", "alice@example.com", 25)
        
        assert len(app.state.users) == 1
        assert user.name == "Alice"
        assert user.email == "alice@example.com"
        assert user.age == 25
    
    def test_add_user_invalid_email(self):
        """Test adding user with invalid email raises error."""
        app = Application()
        with pytest.raises(ValidationError):
            app.add_user("Invalid", "not-email", 25)
    
    def test_list_users(self):
        """Test listing users."""
        app = Application()
        app.add_user("Alice", "alice@example.com")
        app.add_user("Bob", "bob@example.com")
        
        users = app.list_users()
        assert len(users) == 2
        assert users[0].name == "Alice"
        assert users[1].name == "Bob"
    
    def test_get_status(self):
        """Test getting application status."""
        app = Application()
        app.add_user("Alice", "alice@example.com")
        
        status = app.get_status()
        assert status["status"] == "initialized"
        assert status["user_count"] == 1
        assert "config" in status
        assert "metadata" in status
    
    @pytest.mark.asyncio
    async def test_run_demo(self):
        """Test running demo."""
        app = Application()
        await app.initialize()
        
        with patch('builtins.print') as mock_print:
            await app.run_demo()
        
        # Verify users were added
        users = app.list_users()
        assert len(users) == 3
        
        # Verify print was called
        assert mock_print.called


@pytest.mark.integration
class TestIntegration:
    """Integration tests."""
    
    @pytest.mark.asyncio
    async def test_full_application_workflow(self):
        """Test complete application workflow."""
        # Initialize application
        app = Application()
        await app.initialize()
        
        # Add users
        user1 = app.add_user("Alice", "alice@example.com", 30)
        user2 = app.add_user("Bob", "bob@example.com")
        
        # Verify state
        assert len(app.list_users()) == 2
        assert app.state.status == "running"
        
        # Get status
        status = app.get_status()
        assert status["user_count"] == 2
        assert status["status"] == "running"
        
        # Run demo (adds more users)
        await app.run_demo()
        
        # Verify final state
        final_users = app.list_users()
        assert len(final_users) == 5  # 2 + 3 from demo


# Fixtures for testing
@pytest.fixture
def sample_config():
    """Provide a sample configuration."""
    return Config(debug=True, testing=True)


@pytest.fixture
def sample_application(sample_config):
    """Provide a sample application instance."""
    app = Application()
    app.config = sample_config
    return app


@pytest.fixture
def sample_users():
    """Provide sample user data."""
    return [
        ("Alice Johnson", "alice@example.com", 30),
        ("Bob Smith", "bob@example.com", 25),
        ("Carol Williams", "carol@example.com", None),
    ]


# Parameterized tests
@pytest.mark.parametrize("name,email,age,should_succeed", [
    ("Alice", "alice@example.com", 25, True),
    ("Bob", "bob@example.com", None, True),
    ("Carol", "invalid-email", 30, False),
    ("Dave", "dave@example.com", -5, False),
    ("Eve", "eve@example.com", 200, False),
])
def test_user_creation_parametrized(name, email, age, should_succeed):
    """Test user creation with various inputs."""
    if should_succeed:
        user = UserModel(name=name, email=email, age=age)
        assert user.name == name
        assert user.email == email
        assert user.age == age
    else:
        with pytest.raises(ValidationError):
            UserModel(name=name, email=email, age=age)
EOF
}

__print_python_test_utils() {
    local file="$1"
    local package_name="$2"
    
    cat > "$file" << EOF
"""
Tests for utils module.
"""

import pytest
import json
import tempfile
from pathlib import Path
from unittest.mock import patch, mock_open

from ${package_name}.utils import (
    format_message,
    validate_email,
    safe_json_loads,
    safe_json_dumps,
    read_file_safe,
    write_file_safe,
    timer,
    deep_merge_dicts,
    truncate_string,
    retry_with_backoff,
    RetryError
)


class TestFormatMessage:
    """Test message formatting function."""
    
    def test_format_message_info(self):
        """Test formatting info message."""
        result = format_message("info", "Test message")
        assert "INFO" in result
        assert "Test message" in result
        assert result.startswith("[")
    
    def test_format_message_error(self):
        """Test formatting error message."""
        result = format_message("error", "Error occurred")
        assert "ERROR" in result
        assert "Error occurred" in result
    
    def test_format_message_with_colors(self):
        """Test that format includes color codes."""
        result = format_message("success", "Success!")
        # Should contain ANSI color codes
        assert "\\033[" in result
        assert "SUCCESS" in result


class TestValidateEmail:
    """Test email validation function."""
    
    @pytest.mark.parametrize("email,expected", [
        ("user@example.com", True),
        ("test.email@domain.co.uk", True),
        ("user+tag@example.com", True),
        ("user123@test-domain.com", True),
        ("invalid", False),
        ("user@", False),
        ("@example.com", False),
        ("user@.com", False),
        ("user@com", False),
        ("", False),
        (None, False),
        (123, False),
    ])
    def test_validate_email_cases(self, email, expected):
        """Test email validation with various cases."""
        assert validate_email(email) == expected


class TestSafeJsonOperations:
    """Test safe JSON operations."""
    
    def test_safe_json_loads_valid(self):
        """Test loading valid JSON."""
        data = '{"key": "value", "number": 42}'
        result = safe_json_loads(data)
        assert result == {"key": "value", "number": 42}
    
    def test_safe_json_loads_invalid(self):
        """Test loading invalid JSON."""
        data = '{"key": "value"'  # Missing closing brace
        result = safe_json_loads(data)
        assert result is None
    
    def test_safe_json_loads_bytes(self):
        """Test loading JSON from bytes."""
        data = b'{"key": "value"}'
        result = safe_json_loads(data)
        assert result == {"key": "value"}
    
    def test_safe_json_dumps_valid(self):
        """Test dumping valid data."""
        data = {"key": "value", "number": 42}
        result = safe_json_dumps(data)
        parsed = json.loads(result)
        assert parsed == data
    
    def test_safe_json_dumps_with_indent(self):
        """Test dumping with indentation."""
        data = {"key": "value"}
        result = safe_json_dumps(data, indent=2)
        assert "\\n" in result
        assert "  " in result
    
    def test_safe_json_dumps_invalid(self):
        """Test dumping invalid data."""
        # Object that can't be JSON serialized
        class NonSerializable:
            pass
        
        data = {"obj": NonSerializable()}
        result = safe_json_dumps(data)
        # Should not be None because we use default=str
        assert result is not None


class TestFileOperations:
    """Test file operation utilities."""
    
    def test_read_file_safe_existing(self):
        """Test reading existing file."""
        with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
            f.write("test content")
            f.flush()
            
            result = read_file_safe(f.name)
            assert result == "test content"
            
            # Cleanup
            Path(f.name).unlink()
    
    def test_read_file_safe_nonexistent(self):
        """Test reading non-existent file."""
        result = read_file_safe("/nonexistent/file.txt")
        assert result is None
    
    def test_write_file_safe_success(self):
        """Test successful file writing."""
        with tempfile.TemporaryDirectory() as temp_dir:
            file_path = Path(temp_dir) / "test.txt"
            result = write_file_safe(file_path, "test content")
            assert result is True
            assert file_path.read_text() == "test content"
    
    def test_write_file_safe_creates_directory(self):
        """Test that write_file_safe creates directories."""
        with tempfile.TemporaryDirectory() as temp_dir:
            file_path = Path(temp_dir) / "subdir" / "test.txt"
            result = write_file_safe(file_path, "test content")
            assert result is True
            assert file_path.exists()
            assert file_path.read_text() == "test content"


class TestTimer:
    """Test timer context manager."""
    
    def test_timer_context_manager(self):
        """Test timer context manager."""
        with patch('builtins.print') as mock_print:
            with timer("Test operation"):
                pass  # Do nothing
        
        # Should have printed start and end messages
        assert mock_print.call_count >= 2
        calls = [call[0][0] for call in mock_print.call_args_list]
        assert any("Starting Test operation" in call for call in calls)
        assert any("Test operation completed" in call for call in calls)


class TestDeepMergeDicts:
    """Test deep dictionary merging."""
    
    def test_simple_merge(self):
        """Test simple dictionary merge."""
        dict1 = {"a": 1, "b": 2}
        dict2 = {"c": 3, "d": 4}
        result = deep_merge_dicts(dict1, dict2)
        assert result == {"a": 1, "b": 2, "c": 3, "d": 4}
    
    def test_nested_merge(self):
        """Test nested dictionary merge."""
        dict1 = {"a": {"x": 1, "y": 2}, "b": 3}
        dict2 = {"a": {"z": 4}, "c": 5}
        result = deep_merge_dicts(dict1, dict2)
        expected = {"a": {"x": 1, "y": 2, "z": 4}, "b": 3, "c": 5}
        assert result == expected
    
    def test_overwrite_merge(self):
        """Test that dict2 values overwrite dict1."""
        dict1 = {"a": 1, "b": {"x": 10}}
        dict2 = {"a": 2, "b": {"x": 20, "y": 30}}
        result = deep_merge_dicts(dict1, dict2)
        expected = {"a": 2, "b": {"x": 20, "y": 30}}
        assert result == expected


class TestTruncateString:
    """Test string truncation utility."""
    
    def test_no_truncation_needed(self):
        """Test string that doesn't need truncation."""
        result = truncate_string("short", 10)
        assert result == "short"
    
    def test_truncation_with_default_suffix(self):
        """Test truncation with default suffix."""
        result = truncate_string("this is a long string", 10)
        assert result == "this is..."
        assert len(result) == 10
    
    def test_truncation_with_custom_suffix(self):
        """Test truncation with custom suffix."""
        result = truncate_string("long string", 8, suffix=">>")
        assert result == "long s>>"
        assert len(result) == 8
    
    def test_truncation_suffix_longer_than_max(self):
        """Test when suffix is longer than max length."""
        result = truncate_string("text", 2, suffix="...")
        assert result == "te"
        assert len(result) == 2


class TestRetryWithBackoff:
    """Test retry decorator."""
    
    def test_retry_success_on_first_try(self):
        """Test function that succeeds on first try."""
        @retry_with_backoff(max_retries=3)
        def successful_func():
            return "success"
        
        result = successful_func()
        assert result == "success"
    
    def test_retry_success_after_failures(self):
        """Test function that succeeds after some failures."""
        call_count = 0
        
        @retry_with_backoff(max_retries=3, base_delay=0.01)  # Fast for testing
        def flaky_func():
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise ValueError("Temporary failure")
            return "success"
        
        with patch('time.sleep'):  # Mock sleep for faster tests
            result = flaky_func()
        
        assert result == "success"
        assert call_count == 3
    
    def test_retry_exhausted(self):
        """Test function that fails all retry attempts."""
        @retry_with_backoff(max_retries=2, base_delay=0.01)
        def failing_func():
            raise ValueError("Always fails")
        
        with patch('time.sleep'):
            with pytest.raises(RetryError, match="Function failed after 2 retries"):
                failing_func()
    
    def test_retry_specific_exceptions(self):
        """Test retrying only specific exceptions."""
        @retry_with_backoff(max_retries=2, exceptions=(ValueError,))
        def mixed_exception_func():
            raise TypeError("Should not be retried")
        
        # Should not retry TypeError, should fail immediately
        with pytest.raises(TypeError):
            mixed_exception_func()


# Performance and edge case tests
class TestUtilsPerformance:
    """Test utils performance and edge cases."""
    
    def test_large_json_handling(self):
        """Test handling of large JSON data."""
        large_data = {"key_" + str(i): "value_" + str(i) for i in range(1000)}
        
        # Should handle large data without issues
        json_str = safe_json_dumps(large_data)
        assert json_str is not None
        
        parsed = safe_json_loads(json_str)
        assert parsed == large_data
    
    def test_deep_nested_dict_merge(self):
        """Test deep nested dictionary merging."""
        dict1 = {"a": {"b": {"c": {"d": 1}}}}
        dict2 = {"a": {"b": {"c": {"e": 2}}}}
        
        result = deep_merge_dicts(dict1, dict2)
        expected = {"a": {"b": {"c": {"d": 1, "e": 2}}}}
        assert result == expected
    
    @pytest.mark.parametrize("text,max_len,expected_len", [
        ("", 10, 0),
        ("a", 10, 1),
        ("exactly_ten", 10, 10),
        ("more_than_ten_characters", 10, 10),
        ("x" * 100, 20, 20),
    ])
    def test_truncate_various_lengths(self, text, max_len, expected_len):
        """Test truncation with various lengths."""
        result = truncate_string(text, max_len)
        assert len(result) == expected_len
EOF
}

__print_python_conftest() {
    local file="$1"
    
    cat > "$file" << EOF
"""
Pytest configuration and fixtures.
"""

import pytest
import asyncio
from pathlib import Path
from typing import Generator

from ${package_name//-/_}.config import Config


# Configure pytest-asyncio
@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
def test_config() -> Config:
    """Provide a test configuration."""
    return Config(
        debug=True,
        testing=True,
        secret_key="test-secret-key",
        database={
            "host": "localhost",
            "port": 5432,
            "database": "test_db",
            "username": "test_user",
            "password": "test_password"
        },
        logging={
            "level": "DEBUG",
            "file_path": None  # No file logging in tests
        }
    )


@pytest.fixture
def temp_directory(tmp_path) -> Path:
    """Provide a temporary directory for tests."""
    return tmp_path


@pytest.fixture
def sample_json_data():
    """Provide sample JSON data for testing."""
    return {
        "string_field": "test_value",
        "number_field": 42,
        "boolean_field": True,
        "null_field": None,
        "array_field": [1, 2, 3, "four"],
        "object_field": {
            "nested_string": "nested_value",
            "nested_number": 3.14
        }
    }


@pytest.fixture
def sample_users_data():
    """Provide sample user data for testing."""
    return [
        {
            "name": "Alice Johnson",
            "email": "alice@example.com",
            "age": 30
        },
        {
            "name": "Bob Smith", 
            "email": "bob@example.com",
            "age": 25
        },
        {
            "name": "Carol Williams",
            "email": "carol@example.com",
            "age": None
        }
    ]


# Pytest markers
pytest_markers = [
    "unit: marks tests as unit tests",
    "integration: marks tests as integration tests", 
    "slow: marks tests as slow running tests",
    "async: marks tests that use async/await"
]


# Test configuration
def pytest_configure(config):
    """Configure pytest with custom markers."""
    for marker in pytest_markers:
        config.addinivalue_line("markers", marker)


def pytest_collection_modifyitems(config, items):
    """Modify test collection to add markers automatically."""
    for item in items:
        # Mark async tests
        if asyncio.iscoroutinefunction(item.function):
            item.add_marker(pytest.mark.async)
        
        # Mark slow tests based on name
        if "slow" in item.name or "performance" in item.name:
            item.add_marker(pytest.mark.slow)
        
        # Mark integration tests
        if "integration" in item.name or "Integration" in item.cls.__name__ if item.cls else False:
            item.add_marker(pytest.mark.integration)
        else:
            item.add_marker(pytest.mark.unit)
EOF
}

__print_python_gitignore() {
    local file="$1"
    
    cat > "$file" << 'EOF'
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff
instance/
.webassets-cache

# Scrapy stuff
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
Pipfile.lock

# poetry
poetry.lock

# pdm
.pdm.toml

# PEP 582
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
.idea/
EOF
    
    # Add common patterns
    __print_common_gitignore "$file"
}

__print_setup_cfg() {
    local file="$1"
    
    cat > "$file" << 'EOF'
[metadata]
name = attr: src.package.__name__
version = attr: src.package.__version__
author = attr: src.package.__author__
author_email = attr: src.package.__email__

[flake8]
max-line-length = 88
extend-ignore = E203, W503
exclude = 
    .git,
    __pycache__,
    build,
    dist,
    .eggs,
    *.egg-info,
    .venv,
    venv,
    .pytest_cache

[isort]
profile = black
multi_line_output = 3
line_length = 88
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true

[mypy]
python_version = 3.8
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true

[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --strict-markers
    --strict-config
    --verbose
EOF
}

__print_python_version() {
    local file="$1"
    
    cat > "$file" << 'EOF'
3.11.0
EOF
}

__print_makefile() {
    local file="$1"
    local project_name="$2"
    
    cat > "$file" << EOF
# Makefile for $project_name

.PHONY: help install install-dev test test-cov lint format clean build docs

# Default target
help:
	@echo "Available targets:"
	@echo "  install     - Install production dependencies"
	@echo "  install-dev - Install development dependencies"
	@echo "  test        - Run tests"
	@echo "  test-cov    - Run tests with coverage"
	@echo "  lint        - Run linting (flake8, mypy)"
	@echo "  format      - Format code (black, isort)"
	@echo "  clean       - Clean build artifacts"
	@echo "  build       - Build package"
	@echo "  docs        - Generate documentation"

# Installation
install:
	pip install -r requirements.txt

install-dev:
	pip install -r requirements-dev.txt
	pip install -e .

# Testing
test:
	pytest

test-cov:
	pytest --cov=${project_name//-/_} --cov-report=html --cov-report=term

test-fast:
	pytest -x -v

# Linting and formatting
lint:
	flake8 src/ tests/
	mypy src/

format:
	black src/ tests/
	isort src/ tests/

format-check:
	black --check src/ tests/
	isort --check-only src/ tests/

# Cleaning
clean:
	rm -rf build/
	rm -rf dist/
	rm -rf *.egg-info/
	rm -rf htmlcov/
	rm -rf .pytest_cache/
	rm -rf .mypy_cache/
	find . -type d -name __pycache__ -delete
	find . -type f -name "*.pyc" -delete

# Building
build:
	python -m build

build-wheel:
	python -m build --wheel

# Documentation
docs:
	@echo "Documentation generation not configured yet"

# Development workflow
dev-setup: install-dev
	pre-commit install

dev-test: format lint test

dev-clean: clean
	rm -rf .venv/

# CI targets
ci-test: install-dev format-check lint test-cov

# Run the application
run:
	python -m ${project_name//-/_}

# Development server (if applicable)
dev:
	python -m ${project_name//-/_}
EOF
}
            